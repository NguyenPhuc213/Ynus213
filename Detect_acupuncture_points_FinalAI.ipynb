{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Detect_acupuncture_points_FinalAI.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMuofZCQYuoabZQ5FWTcysx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NguyenPhuc213/Ynus213/blob/main/Detect_acupuncture_points_FinalAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pi7e5Mvh1fG8"
      },
      "outputs": [],
      "source": [
        "#GetImageFromVideo \n",
        "#Code này chạy trên VS Code sau đó load data lên ColabColab\n",
        "import cv2\n",
        "import time\n",
        "\n",
        "def main():\n",
        "    cap = cv2.VideoCapture('D:\\_PHUC\\_SV19\\HK II 2021 - 2022\\Thi giac may\\Video source\\BanPhuc.mp4')\n",
        "    # Resolution 640*480\n",
        "    time.sleep(1)\n",
        "    if cap is None or not cap.isOpened():\n",
        "        print('Khong the mo file video')\n",
        "        return\n",
        "    cv2.namedWindow('Image', cv2.WINDOW_AUTOSIZE);\n",
        "    n = 1\n",
        "    dem = 0\n",
        "    while True:\n",
        "        [success, img] = cap.read()\n",
        "        ch = cv2.waitKey(30)\n",
        "        if success:       \n",
        "            imgROI = img[180:(480+680),50:(300+480)] # Tao ra anh 680x480\n",
        "\n",
        "            imgROI = cv2.resize(imgROI,(250,250))\n",
        "            cv2.imshow('Image', imgROI)\n",
        "        else:\n",
        "            break\n",
        "        if n%4 == 0:\n",
        "            filename = 'D:\\_PHUC\\_SV19\\HK II 2021 - 2022\\Thi giac may\\Image_Video\\BanPhuc\\BanPhuc_%04d.bmp'%(dem)\n",
        "            cv2.imwrite(filename,imgROI)\n",
        "            dem = dem + 1\n",
        "        n = n + 1\n",
        "    return\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPool2D, BatchNormalization\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "import cv2\n",
        "from os import listdir\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer"
      ],
      "metadata": {
        "id": "8JyxjUcA2UAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount = True)"
      ],
      "metadata": {
        "id": "vkgH6sVw2d6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_history(history_fine):\n",
        "  f1 = history_fine.history['acc']\n",
        "  val_f1 = history_fine.history['val_acc']\n",
        "  loss = history_fine.history['loss']\n",
        "  val_loss = history_fine.history['val_loss']\n",
        "  plt.figure(figsize=(8, 8))\n",
        "  plt.subplot(2, 1, 1)\n",
        "  plt.plot(f1, label='Acc')\n",
        "  plt.plot(val_f1, label='Validation Acc')\n",
        "  plt.legend(loc='lower right')\n",
        "  plt.title('Accuracy')\n",
        "  plt.subplot(2, 1, 2)\n",
        "  plt.plot(loss, label='Loss')\n",
        "  plt.plot(val_loss, label='Validation Loss')\n",
        "  plt.legend(loc='upper right')\n",
        "  plt.title('Loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "0V1gVVIa2elq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_img_dataset(raw_folder,dataset_name):\n",
        "\n",
        "    target_size = (680, 480)\n",
        "    pictures = []\n",
        "    labels = []\n",
        "    for folder in listdir(raw_folder):\n",
        "      for file in listdir(raw_folder + \"/\" + folder)[:1000]:\n",
        "        pictures.append(cv2.resize(cv2.imread(raw_folder + \"/\" + folder + \"/\" + file,cv2.IMREAD_GRAYSCALE)\n",
        "                                              ,dsize = target_size))\n",
        "        labels.append(folder)\n",
        "\n",
        "    pictures = np.array(pictures)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    encoder = LabelBinarizer()\n",
        "    labels = encoder.fit_transform(labels)\n",
        "\n",
        "    with open (dataset_name, mode = 'wb') as file:\n",
        "    # dump information to that file\n",
        "      pickle.dump((pictures,labels), file)\n",
        "\n",
        "    file.close()\n",
        "\n",
        "def load_data(dataset_path):\n",
        "\n",
        "    file = open(dataset_path, mode = 'rb')\n",
        "    (pictures, labels) = pickle.load (file)\n",
        "    file.close()\n",
        "\n",
        "    return pictures, labels"
      ],
      "metadata": {
        "id": "_PNKDCJN2ihq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_folder = \"/content/drive/MyDrive/BanPhuc\"\n",
        "\n",
        "create_img_dataset(raw_folder= raw_folder,dataset_name= 'data.pickle')\n",
        "dataset_path = \"data.pickle\""
      ],
      "metadata": {
        "id": "YLrDti1O2szq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_DATA_PATH = 'data.pickle'\n",
        "Y_DATA_PATH = 'train.csv'"
      ],
      "metadata": {
        "id": "Hm8XEaQq3AmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "y_data = pd.read_csv(Y_DATA_PATH)\n",
        "y_data.head(None)"
      ],
      "metadata": {
        "id": "FfloKX893FJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import pickle\n",
        "import numpy as np\n",
        "x_data = pickle.load(open(X_DATA_PATH, 'rb'))\n",
        "x_data = np.array(x_data, dtype = 'float')\n",
        "x_data /= 255\n",
        "print('Shape of x data: ', x_data.shape)"
      ],
      "metadata": {
        "id": "nD5e6Zge3LPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pylab as plt\n",
        "import pandas as pd\n",
        "import random\n",
        "import cv2\n",
        "\n",
        "n = x_data.shape[0]\n",
        "plt.figure(figsize = (15, 15))\n",
        "plt.subplots_adjust(hspace = .2)\n",
        "for i in range(6):\n",
        "    plt.subplot(3, 2, i + 1)\n",
        "    k = random.randint(0, 299)\n",
        "    img = x_data[k]\n",
        "    points = list(y_data.iloc[k])\n",
        "    points = [tuple(points[i : i + 2]) for i in range(0, len(points), 2)]\n",
        "    for x, y in points:\n",
        "        cv2.circle(img, (int(x), int(y)), 2, (0, 0, 0), 2)\n",
        "    plt.imshow(img)\n",
        "\n",
        "_ = plt.suptitle('Sample images', size = 20)"
      ],
      "metadata": {
        "id": "MKi0Phug3N-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "#x_data = x_data.reshape(-1, (150,150), 1)\n",
        "input_shape = x_data.shape[1:4]\n",
        "y_data = np.array(y_data, dtype = 'float')\n",
        "num_class = y_data.shape[1]\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 0.1)\n",
        "print('Input shape: ', input_shape)\n",
        "print('Number of output: ', num_class)\n",
        "print('x train shape: ', x_train.shape)\n",
        "print('y train shape: ', y_train.shape)\n",
        "print('x test shape: ', x_test.shape)\n",
        "print('y test shape: ', y_test.shape)"
      ],
      "metadata": {
        "id": "CtE2Ygz73OpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Conv2D, Dropout, BatchNormalization, MaxPooling2D, Flatten, LeakyReLU, Convolution2D, MaxPool2D\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Convolution2D(32, (3,3), padding='same', use_bias=False, input_shape = input_shape))\n",
        "model.add(LeakyReLU(alpha = 0.1))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(32, (3,3), padding='same', use_bias=False))\n",
        "model.add(LeakyReLU(alpha = 0.1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Convolution2D(64, (3,3), padding='same', use_bias=False))\n",
        "model.add(LeakyReLU(alpha = 0.1))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(64, (3,3), padding='same', use_bias=False))\n",
        "model.add(LeakyReLU(alpha = 0.1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "# Dense\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation = 'relu'))\n",
        "# model.add(Dense(num_class, activation='softmax'))\n",
        "model.add(Dense(num_class))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "xBpIqJ2A3VNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "model.compile(\n",
        "    optimizer = 'Adam',\n",
        "    loss = \"mean_squared_error\",\n",
        "    metrics = ['mae']\n",
        ")"
      ],
      "metadata": {
        "id": "IduNLH-83YJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "callback = EarlyStopping(monitor = 'val_mae', patience = 25)\n",
        "hist = model.fit(x_train, y_train, epochs = 100, batch_size = 16, validation_split = 0.1).history"
      ],
      "metadata": {
        "id": "7SC9U-b_3aoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_loss, final_accuracy = model.evaluate(x_test, y_test)\n",
        "print('Final loss: {:.2f}'.format(final_loss))\n",
        "print('Final accuracy: {:.2f}'.format(final_accuracy))"
      ],
      "metadata": {
        "id": "2wRDIora3cwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pylab as plt\n",
        "model_history = pd.DataFrame(hist)\n",
        "# add epoch column\n",
        "model_history['epoch'] = np.arange(1, len(model_history) + 1)\n",
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize = (8, 10))\n",
        "epochs = model_history.shape[0]\n",
        "ax1.plot(np.arange(0, epochs), model_history['mae'], label = 'Training accuracy')\n",
        "ax1.plot(np.arange(0, epochs), model_history['val_mae'], label = 'Validation accuracy')\n",
        "ax1.legend(loc = 'lower right')\n",
        "ax1.set_ylabel('Accuracy')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax2.plot(np.arange(0, epochs), model_history['loss'], label = 'Training loss')\n",
        "ax2.plot(np.arange(0, epochs), model_history['val_loss'], label = 'Validation loss')\n",
        "ax2.legend(loc = 'upper right')\n",
        "ax2.set_ylabel('Loss')\n",
        "ax2.set_xlabel('Epoch')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DZFcJkMl3fBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = '/content/drive/MyDrive/AI/'\n",
        "MODEL_NAME = \"Model_MAE\" + str(round(final_accuracy)) + \".h5\"\n",
        "model.save(PATH + MODEL_NAME)"
      ],
      "metadata": {
        "id": "tWSP9fMK362p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model = load_model(PATH + MODEL_NAME)"
      ],
      "metadata": {
        "id": "fWrZxywb39sh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pylab as plt\n",
        "import cv2\n",
        "pred = model.predict(x_test)\n",
        "n = x_test.shape[0]\n",
        "plt.figure(figsize = (15, 15))\n",
        "plt.subplots_adjust(hspace = .2)\n",
        "plt.subplot(3, 2, i + 1)\n",
        "#k = random.randint(0, 10)\n",
        "k= 0\n",
        "img = x_test[k].reshape(150,150,3)\n",
        "points = pred[k,:]\n",
        "#points = [tuple(points[i : i + 2]) for i in range(0, len(points), 2)]\n",
        "print(points)\n",
        "cv2.circle(img, (int(x), int(y)), 2, (0, 0, 0), 2)\n",
        "plt.imshow(img)  \n",
        "_ = plt.suptitle('Sample images', size = 20)"
      ],
      "metadata": {
        "id": "LUu7JFG_3_mw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}